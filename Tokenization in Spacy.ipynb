{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0427a0c3",
   "metadata": {},
   "source": [
    "# Tokenization in Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "366d27e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import paskages \n",
    "import spacy\n",
    "\n",
    "from spacy.symbols import ORTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06e684b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creat object\n",
    "nlp= spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a73e811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Dr. Ali loves Red bees of china as it costs only 2$ per plate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ece61d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr.\n",
      "Ali\n",
      "loves\n",
      "Red\n",
      "bees\n",
      "of\n",
      "china\n",
      "as\n",
      "it\n",
      "costs\n",
      "only\n",
      "2\n",
      "$\n",
      "per\n",
      "plate\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a4dfe28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dr."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dfcb73f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ali"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8901a611",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5789702a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdd48c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\n",
      "Let\n",
      "'s\n",
      "go\n",
      "to\n",
      "N.Y\n",
      "!\n",
      "\"\n"
     ]
    }
   ],
   "source": [
    "#ex2\n",
    "doc_2= nlp('''\"Let's go to N.Y!\"''')\n",
    "for token in doc_2:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3e1e1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27ddd348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.lang.en.English"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print type object \n",
    "type(nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "292ec2ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print type doc\n",
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a96804c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0597c049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ali loves Red bees"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ad17c831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span = doc[1:5]\n",
    "type(span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1706553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c83bcb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2a376c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc= nlp(\"Tony gave two $ to Peter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4632fbcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tony"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_0= doc[0]\n",
    "token_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c236d245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.token.Token"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(token_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3dc04dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_',\n",
       " '__bytes__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__pyx_vtable__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__unicode__',\n",
       " 'ancestors',\n",
       " 'check_flag',\n",
       " 'children',\n",
       " 'cluster',\n",
       " 'conjuncts',\n",
       " 'dep',\n",
       " 'dep_',\n",
       " 'doc',\n",
       " 'ent_id',\n",
       " 'ent_id_',\n",
       " 'ent_iob',\n",
       " 'ent_iob_',\n",
       " 'ent_kb_id',\n",
       " 'ent_kb_id_',\n",
       " 'ent_type',\n",
       " 'ent_type_',\n",
       " 'get_extension',\n",
       " 'has_dep',\n",
       " 'has_extension',\n",
       " 'has_head',\n",
       " 'has_morph',\n",
       " 'has_vector',\n",
       " 'head',\n",
       " 'i',\n",
       " 'idx',\n",
       " 'iob_strings',\n",
       " 'is_alpha',\n",
       " 'is_ancestor',\n",
       " 'is_ascii',\n",
       " 'is_bracket',\n",
       " 'is_currency',\n",
       " 'is_digit',\n",
       " 'is_left_punct',\n",
       " 'is_lower',\n",
       " 'is_oov',\n",
       " 'is_punct',\n",
       " 'is_quote',\n",
       " 'is_right_punct',\n",
       " 'is_sent_end',\n",
       " 'is_sent_start',\n",
       " 'is_space',\n",
       " 'is_stop',\n",
       " 'is_title',\n",
       " 'is_upper',\n",
       " 'lang',\n",
       " 'lang_',\n",
       " 'left_edge',\n",
       " 'lefts',\n",
       " 'lemma',\n",
       " 'lemma_',\n",
       " 'lex',\n",
       " 'lex_id',\n",
       " 'like_email',\n",
       " 'like_num',\n",
       " 'like_url',\n",
       " 'lower',\n",
       " 'lower_',\n",
       " 'morph',\n",
       " 'n_lefts',\n",
       " 'n_rights',\n",
       " 'nbor',\n",
       " 'norm',\n",
       " 'norm_',\n",
       " 'orth',\n",
       " 'orth_',\n",
       " 'pos',\n",
       " 'pos_',\n",
       " 'prefix',\n",
       " 'prefix_',\n",
       " 'prob',\n",
       " 'rank',\n",
       " 'remove_extension',\n",
       " 'right_edge',\n",
       " 'rights',\n",
       " 'sent',\n",
       " 'sent_start',\n",
       " 'sentiment',\n",
       " 'set_extension',\n",
       " 'set_morph',\n",
       " 'shape',\n",
       " 'shape_',\n",
       " 'similarity',\n",
       " 'subtree',\n",
       " 'suffix',\n",
       " 'suffix_',\n",
       " 'tag',\n",
       " 'tag_',\n",
       " 'tensor',\n",
       " 'text',\n",
       " 'text_with_ws',\n",
       " 'vector',\n",
       " 'vector_norm',\n",
       " 'vocab',\n",
       " 'whitespace_']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(token_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e0422104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_0.is_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5672cf7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_0.like_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "04bde0c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'two'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_2= doc[2]\n",
    "token_2.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9adb0de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_2.like_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "919e0c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'$'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_3= doc[3]\n",
    "token_3.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "98eab3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_3.like_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "83fab157",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_3.is_currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74cd0880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b2f2386c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tony ==> index: 0 |is_alpha:  True | is_punct:  False | like_num:  False | is_currency:  False\n",
      "gave ==> index: 1 |is_alpha:  True | is_punct:  False | like_num:  False | is_currency:  False\n",
      "two ==> index: 2 |is_alpha:  True | is_punct:  False | like_num:  True | is_currency:  False\n",
      "$ ==> index: 3 |is_alpha:  False | is_punct:  False | like_num:  False | is_currency:  True\n",
      "to ==> index: 4 |is_alpha:  True | is_punct:  False | like_num:  False | is_currency:  False\n",
      "Peter ==> index: 5 |is_alpha:  True | is_punct:  False | like_num:  False | is_currency:  False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token , \"==>\" , 'index:',token.i ,\"|\"\n",
    "          'is_alpha: ' , token.is_alpha,\"|\",\n",
    "          \"is_punct: \",token.is_punct,\"|\",\n",
    "          \"like_num: \",token.like_num,\"|\",\n",
    "           \"is_currency: \",token.is_currency\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499f808a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a597ed0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9a81ee37",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ab4afe8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dayton high school, 8th grade students information\\n',\n",
       " '==================================================\\n',\n",
       " '\\n',\n",
       " 'Name\\tbirth day   \\temail\\n',\n",
       " '-----\\t------------\\t------\\n',\n",
       " 'Virat   5 June, 1882    virat@kohli.com\\n',\n",
       " 'Maria\\t12 April, 2001  maria@sharapova.com\\n',\n",
       " 'Serena  24 June, 1998   serena@williams.com \\n',\n",
       " 'Joe      1 May, 1997    joe@root.com\\n',\n",
       " '\\n',\n",
       " '\\n',\n",
       " '\\n']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load file text \n",
    "with open(\"data/students.txt\") as f:\n",
    "    text = f.readlines()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1948970b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dayton high school, 8th grade students information\\n ==================================================\\n \\n Name\\tbirth day   \\temail\\n -----\\t------------\\t------\\n Virat   5 June, 1882    virat@kohli.com\\n Maria\\t12 April, 2001  maria@sharapova.com\\n Serena  24 June, 1998   serena@williams.com \\n Joe      1 May, 1997    joe@root.com\\n \\n \\n \\n'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Join lines with 'tab'\n",
    "text = \" \".join(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "ff2d5055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get email from te text \n",
    "doc= nlp(text)\n",
    "email=[] ## Initialize an empty list to store email addresses\n",
    "for token in doc:\n",
    "    if token.like_email: # # Check if the token looks like an email \n",
    "        email.append(token.text)## If it , append it to the email list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "a2fb81bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['virat@kohli.com',\n",
       " 'maria@sharapova.com',\n",
       " 'serena@williams.com',\n",
       " 'joe@root.com']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print emails \n",
    "email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6187ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "863bc526",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "26531901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "علي\n",
      "يحب\n",
      "القتال\n",
      "بالنار\n",
      "كل\n",
      "3\n",
      "ايام\n"
     ]
    }
   ],
   "source": [
    "#with language arabic  # \n",
    "nlp= spacy.blank(\"ar\")\n",
    "doc=nlp(\"علي يحب القتال بالنار كل 3 ايام\")\n",
    "#print words\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "70ccf64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_4=doc[-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d6a70b6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_4.like_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8706ff14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['علي', 'يحب', 'القتال', 'بالنار', 'كل', '3', 'ايام']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print words used list \n",
    "tokens = [token.text for token in doc]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c74c4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5120dc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98d32f5",
   "metadata": {},
   "source": [
    "### Customizing tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "09f10d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp= spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "a2e796c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc= nlp(\"gimme double cheese extra large healthy pizza\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "4a4e02fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gimme', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens=[token.text for token in doc]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9655e072",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a custom tokenizer for handling\n",
    "nlp.tokenizer.add_special_case(\"gimme\",[\n",
    "    {ORTH:\"gim\"}, {ORTH :\"me\"}\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f67e3876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gim', 'me', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc= nlp(\"gimme double cheese extra large healthy pizza\")\n",
    "tokens=[token.text for token in doc]\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fd5605",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "207409e6",
   "metadata": {},
   "source": [
    "#### Sentence Tokenization or Segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "30c383a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr.\n",
      "Strange\n",
      "loves\n",
      "pav\n",
      "bhaji\n",
      "of\n",
      "mumbai\n",
      ".\n",
      "Hulk\n",
      "loves\n",
      "chat\n",
      "of\n",
      "delhi\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")\n",
    "for sentence in doc:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "930646a7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11856\\1129431677.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\spacy\\tokens\\doc.pyx\u001b[0m in \u001b[0;36msents\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`."
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")\n",
    "for sentence in doc.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b9c66dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "509c5fb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x1fb59207040>"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe('sentencizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "de32b434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Strange loves pav bhaji of mumbai.\n",
      "Hulk loves chat of delhi\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Dr. Strange loves pav bhaji of mumbai. Hulk loves chat of delhi\")\n",
    "for sentence in doc.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7d7fd651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('sentencizer', <spacy.pipeline.sentencizer.Sentencizer at 0x1fb59207040>)]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb552f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
